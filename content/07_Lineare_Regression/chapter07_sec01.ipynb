{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c0d44f",
   "metadata": {},
   "source": [
    "# 7.1 Einfache lineare Regression\n",
    "\n",
    "Die lineare Regression gehört zu den überwachten maschinellen Lernverfahren\n",
    "(Supervised Learning). Meist ist sie das erste ML-Modell, das eingesetzt wird,\n",
    "um Regressionsprobleme zu lösen. In diesem Kapitel führen wir in das Konzept\n",
    "und die Umsetzung der einfachen linearen Regression mit Scikit-Learn ein.\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "* Sie kennen das **lineare Regressionsmodell**.\n",
    "* Sie können erklären, was die **Fehlerquadratsumme** ist.\n",
    "* Sie wissen, dass das Training des lineare Regressionsmodells durch die\n",
    "  **Minimierung** der Fehlerquadratsumme (Kleinste-Quadrate-Schätzer) erfolgt.\n",
    "* Sie können mit Scikit-Learn ein lineares Regressionsmodell trainieren.\n",
    "* Sie können mit einem trainierten linearen Regressionsmodell Prognosen treffen.\n",
    "* Sie können mit dem **Bestimmtheitsmaß** bzw. **R²-Score** beurteilen, ob das\n",
    "  lineare Regressionsmodell geeignet zur Erklärung der Daten ist.\n",
    "\n",
    "## Regression kommt aus der Statistik\n",
    "\n",
    "In der Statistik beschäftigen sich Mathematikerinnen und Mathematiker bereits\n",
    "seit Jahrhunderten damit, Analyseverfahren zu entwickeln, mit denen\n",
    "experimentelle Daten gut erklärt werden können. Falls wir eine \"erklärende”\n",
    "Variable haben und wir versuchen, die Abhängigkeit einer Messgröße von der\n",
    "erklärenden Variable zu beschreiben, nennen wir das Regressionsanalyse oder kurz\n",
    "**Regression**. Bei vielen Problemen suchen wir nach einem linearen Zusammenhang\n",
    "und sprechen daher von **linearer Regression**. Mehr Details finden wir auch bei\n",
    "[Wikipedia → Regressionsanalyse](https://de.wikipedia.org/wiki/Regressionsanalyse).\n",
    "\n",
    "Etwas präziser formuliert ist lineare Regression ein Verfahren, bei dem es eine\n",
    "Einflussgröße $x$ und eine Zielgröße $y$ gibt. In der ML-Sprechweise wird die\n",
    "Einflussgröße $x$ typischerweise als **Merkmal** (oder englisch **Input** oder\n",
    "**Feature**) bezeichnet. Die **Zielgröße** (manchmal auch **Output** oder\n",
    "**Target** genannt) soll stetig sein (manchmal auch kontinuierlich, metrisch\n",
    "oder quantitativ genannt). Für das Merkmal (oder die Merkmale) liegen $M$\n",
    "Datenpunkte mit den dazugehörigen Werten der Zielgröße vor. Diese werden\n",
    "üblicherweise als Paare (wenn nur ein Merkmal vorliegt) zusammengefasst:\n",
    "\n",
    "$$(x^{(1)},y^{(1)}), \\, (x^{(2)},y^{(2)}), \\, \\ldots, \\, (x^{(M)},y^{(M)}).$$\n",
    "\n",
    "Ziel der linearen Regression ist es, zwei Parameter $w_0$ und $w_1$ so zu\n",
    "bestimmen, so dass die lineare Gleichung\n",
    "\n",
    "$$y^{(i)} \\approx w_0 + w_1 x^{(i)}$$\n",
    "\n",
    "möglichst für alle Datenpunkte $(x^{(i)}, y^{(i)})$ gilt. Geometrisch\n",
    "ausgedrückt: durch die Daten soll eine Gerade gelegt werden, wie die folgende\n",
    "Abbildung zeigt. Die Datenpunkte sind blau, die Regressionsgerade rot.\n",
    "\n",
    "![https://gramschs.github.io/book_ml4ing/_images/Linear_regression.svg](https://gramschs.github.io/book_ml4ing/_images/Linear_regression.svg)\n",
    "\n",
    "Lineare Regression: die erklärende Variable (= Input oder unabhängige Variable\n",
    "oder Ursache) ist auf der x-Achse, die abhängige Variable (= Output oder\n",
    "Wirkung) ist auf der y-Achse aufgetragen, Paare von Messungen sind in blau\n",
    "gekennzeichnet, das Modell in rot.\n",
    "([Quelle:](https://en.wikipedia.org/wiki/Linear_regression#/media/File:Linear_regression.svg)\n",
    "\"Example of simple linear regression, which has one independent variable\" von\n",
    "Sewaqu. Lizenz: Public domain))\n",
    "\n",
    "In der Praxis werden die Daten nicht perfekt auf der Geraden liegen. Die Fehler\n",
    "zwischen dem echten $y^{(i)}$ und dem Funktionswert der Gerade $f(x^{(i)}) = w_0 +\n",
    "w_1 x^{(i)}$ werden unterschiedlich groß sein, je nachdem, welche Parameter\n",
    "$w_0$ und $w_1$ gewählt werden. Wie finden wir jetzt die beste Kombination $w_0$\n",
    "und $w_1$, so dass diese Fehler möglichst klein sind?\n",
    "\n",
    "## Wie groß ist der Fehler?\n",
    "\n",
    "Das Prinzip für das lineare Regressionsmodell und auch die folgenden ML-Modelle\n",
    "ist jedesmal gleich. Das Modell ist eine mathematische Funktion, die aber noch\n",
    "Parameter (hier beispielsweise die Koeffizienten der Gerade) enthält. Dann wird\n",
    "festgelegt, was eine gute Prognose ist, also wie Fehler berechnet und beurteilt\n",
    "werden sollen. Das hängt jeweils von dem betrachteten Problem ab. Sobald das\n",
    "sogenannte Fehlermaß feststeht, werden die Parameter der Modellfunktion so\n",
    "berechnet, dass das Fehlermaß (z.B. Summe der Fehler oder Mittelwert der Fehler)\n",
    "möglichst klein wird. In der Mathematik sagt man dazu **Minimierungsproblem**.\n",
    "\n",
    "Für die lineare Regression wird als Fehlermaß die Kleinste-Quadrate-Schätzung\n",
    "verwendet (siehe [Wikipedia  → Methode der kleinsten\n",
    "Quadrate](https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate)). Dazu\n",
    "berechnen wir, wie weit weg die Gerade von den Messpunkten ist. Wie das geht,\n",
    "veranschaulichen wir uns mit der folgenden Grafik.\n",
    "\n",
    "![https://gramschs.github.io/book_ml4ing/_images/kq_regression.png](https://gramschs.github.io/book_ml4ing/_images/kq_regression.png)\n",
    "\n",
    "Messpunkte (blau) und der Abstand (grün) zu einer Modellfunktion (rot)\n",
    "([Quelle:](https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate#/media/Datei:MDKQ1.svg) Autor: Christian Schirm, Lizenz: CC0)\n",
    "\n",
    "Unsere rote Modellfunktion trifft die Messpunkte mal mehr und mal weniger gut.\n",
    "Wir können jetzt für jeden Messpunkt berechnen, wie weit die rote Kurve von ihm\n",
    "weg ist (= grüne Strecke), indem wir die Differenz der y-Koordinaten errechnen:\n",
    "$r = y_{\\text{blau}}-y_{\\text{rot}}$. Diese Differenz nennt man **Residuum**.\n",
    "Danach summieren wir die Fehler (also die Residuen) auf und erhalten den\n",
    "Gesamtfehler. Dabei kann es passieren, dass am Ende als Gesamtfehler 0\n",
    "herauskommt, weil beispielsweise für den 1. Messpunkt die blaue y-Koordinate\n",
    "unter der roten y-Koordinate liegt und damit ein negatives Residuum herauskommt,\n",
    "aber für den 5. Messpunkt ein positives Residuum. Daher quadrieren wir die\n",
    "Residuen, was noch weitere Vorteile bietet (Differenzierbarkeit, eindeutiges\n",
    "Minimum). Dann wird diese **Fehlerquadratsumme** minimiert, um die Koeffizienten\n",
    "des Regressionsmodells zu berechnen.\n",
    "\n",
    "## Einfache lineare Regression mit Scikit-Learn\n",
    "\n",
    "Nach diesem theoretischen Exkurs möchten wir Scikit-Learn nutzen, um eine\n",
    "einfache lineare Regression durchzuführen. Aus didaktischen Gründen erzeugen wir\n",
    "uns dazu künstliche Daten mit der Funktion `make_regression` des Moduls\n",
    "`sklearn.datasets`. Wir transformieren die zufällig erzeugten Zahlen und packen\n",
    "sie in ein Pandas-DataFrame mit den Merkmalen »Leistung \\[PS\\]« eines Autos und\n",
    "dem »Preis \\[EUR\\]« eines Autos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_array, y_array = make_regression(n_samples=100, n_features=1, noise=10, random_state=0)\n",
    "\n",
    "daten = pd.DataFrame({\n",
    "    'Leistung [PS]': np.floor(50*(X_array[:,0] + 3)),\n",
    "    'Preis [EUR]': 100*(y_array+150)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675d30b",
   "metadata": {},
   "source": [
    "Mehr Details zu der Funktion `make_regression` gibt es in der [Dokumentation\n",
    "Scikit-Learn →\n",
    "make_regression](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression).\n",
    "Wir visualisieren nun den Preis in Abhängigkeit von der Leistung des Autos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "fig = px.scatter(daten, x = 'Leistung [PS]', y = 'Preis [EUR]',\n",
    "    title='Künstliche Daten: Verkaufspreise Autos')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a23a9a",
   "metadata": {},
   "source": [
    "Es drängt sich die Vermutung auf, dass der Preis eines Autos linear von der\n",
    "Leistung abhängt. Je mehr PS, desto teurer das Auto.\n",
    "\n",
    "Als nächstes trainieren wir ein lineares Regressionsmodell auf den Daten.\n",
    "Lineare ML-Modelle fasst Scikit-Learn in einem Untermodul namens `linear_model`\n",
    "zusammen. Um also das lineare Regressionsmodell `LinearRegression` verwenden zu\n",
    "können, müssen wir es folgendermaßen importieren und initialisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7aeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modell = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e634080",
   "metadata": {},
   "source": [
    "Mit der Methode `.fit()` werden die Parameter des linearen Regressionsmodells an\n",
    "die Daten angepasst. Dazu müssen die Daten in einem bestimmten Format vorliegen.\n",
    "Bei den Inputs wird davon ausgegangen, dass mehrere Merkmale in das Modell\n",
    "eingehen sollen. Die Merkmale stehen normalerweise in den Spalten des\n",
    "Datensatzes. Beim Output erwarten wir zunächst nur ein Merkmal, das durch das\n",
    "Modell erklärt werden soll. Daher geht Scikit-Learn davon aus, dass der Input\n",
    "eine Tabelle (Matrix) $X$ ist, die M Zeilen und N Spalten hat. M ist die Anzahl\n",
    "an Datenpunkten, hier also die Anzahl der Autos, und N ist die Anzahl der\n",
    "Merkmale, die betrachtet werden sollen. Da wir momentan nur die Abhängigkeit des\n",
    "Preises von der PS-Zahl analysieren wollen, ist $N=1$. Beim Output geht\n",
    "Scikit-Learn davon aus, dass eine Datenreihe (eindimensionaler Spaltenvektor)\n",
    "vorliegt, die natürlich ebenfalls M Zeilen hat. Wir müssen daher unsere\n",
    "PS-Zahlen noch in das Matrix-Format bringen. Dazu verwenden wir die Tatsache,\n",
    "dass mit `[ [list] ]` eine Tabelle extrahiert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaption der Daten\n",
    "X = daten[['Leistung [PS]']]\n",
    "y = daten['Preis [EUR]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d3234",
   "metadata": {},
   "source": [
    "Danach können wir das lineare Regressionsmodell trainieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd07419",
   "metadata": {},
   "outputs": [],
   "source": [
    "modell.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e503e",
   "metadata": {},
   "source": [
    "Es erfolgt keine Ausgabe, aber jetzt ist das lineare Regressionsmodell\n",
    "trainiert. Die durch das Training bestimmten Parameter des Modells sind im\n",
    "Modell selbst abgespeichert. Bei dem linearen Regressionsmodell sind das die\n",
    "beiden Parameter $w_0$ und $w_1$, also Steigung `.coef_` und den\n",
    "y-Achsenabschnitt `.intercept_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Steigung: {modell.coef_[0]}')\n",
    "print(f'y-Achsenabschnitt: {modell.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b955b",
   "metadata": {},
   "source": [
    "Damit lautet das (gerundete) lineare Regressionsmodell, um aus der PS-Zahl eines\n",
    "Autos $x$ den Verkaufspreis $y$ zu berechnen, folgendermaßen:\n",
    "\n",
    "$$y = 85.2 \\cdot x + 2179.$$\n",
    "\n",
    "## Prognosen treffen\n",
    "\n",
    "Wenn wir die Parameter des trainierten Modells ausgeben lassen bzw. die lineare\n",
    "Funktion $y = 85.2 \\cdot x + 2179$ verwenden, können wir mit dem linearen Modell\n",
    "Prognosen treffen. Den Umweg über das Ausgeben der trainierten Parameter und dem\n",
    "Basteln einer linearen Funktion können wir uns aber sparen, denn Scikit-Learn\n",
    "stellt für Prognosen mit dem trainierten Modell direkt eine Methode zur\n",
    "Verfügung. Mit Hilfe der `predict()`-Methode können für jedes Scikit-ML-Modell\n",
    "Prognosen getroffen werden.\n",
    "\n",
    "Wir möchten uns den kompletten Bereich zwischen 20 PS und 270 PS ansehen und\n",
    "erzeugen daher 100 Punkte in diesem Bereich. Diese transformieren wir in ein\n",
    "Pandas-DataFrame und verwenden dann die `predict()`-Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c503f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdaten = pd.DataFrame({\n",
    "    'Leistung [PS]': np.linspace(20, 270, 100)\n",
    "    })\n",
    "prognose = modell.predict(testdaten[['Leistung [PS]']])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd340dc3",
   "metadata": {},
   "source": [
    "Diese Prognose wird dann zusammen mit den Verkaufsdaten in einem Diagramm\n",
    "visualisiert. Dazu generieren wir zuerst den Scatter-Plot mit den Verkaufsdaten\n",
    "und fügen dann mit der Funktion `add_scatter()` einen zweiten Scatter-Plot zu\n",
    "dem ersten hinzu. In diesem Scatter-Plot sollen die Punkte jedoch durch eine\n",
    "Linie verbunden werden, weshalb wir die Option `mode='lines'` nutzen. Zusätzlich\n",
    "kennzeichnen wir die Regressionsgerade noch mit dem Namen `name='Prognose'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e74723",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(daten, x = 'Leistung [PS]', y = 'Preis [EUR]',\n",
    "    title='Verkaufspreise von Autos')\n",
    "fig.add_scatter(x = testdaten['Leistung [PS]'], y = prognose, mode='lines', name='Prognose')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa756978",
   "metadata": {},
   "source": [
    "Der visuelle Eindruck ist gut, aber ist diese Regressionsgerade wirklich das\n",
    "beste Modell? Im nächsten Abschnitt sehen wir uns ein statistisches Bewertungsmaß\n",
    "an, um die Güte des Modells zu beurteilen.\n",
    "\n",
    "## Ist das beste Modell gut genug? Der R²-Score\n",
    "\n",
    "Auch wenn wir mit der Minimierung der Fehlerquadratsumme bzw. der\n",
    "Kleinsten-Quadrate-Methode die besten Parameter für unsere Modellfunktion\n",
    "gefunden haben, heißt das noch lange nicht, dass unser Modell gut ist. Bereits\n",
    "die Modellfunktion kann ja völlig falsch gewählt sein. Beispielsweise könnten\n",
    "wir Messungen rund um eine sinus-förmige Wechselspannung vornehmen und dann wäre\n",
    "ein lineares Regressionsmodell völlig ungeeignet, auch wenn die\n",
    "Fehlerquadratsumme minimal wäre.\n",
    "\n",
    "Wir brauchen daher noch ein Kriterium dafür, ob das trainierte Modell auch\n",
    "valide ist. Für die lineare Regression nehmen wir das **Bestimmtheitsmaß**, das\n",
    "in der ML-Community auch **R²-Score** genannt wird. Der R²-Score wird dabei\n",
    "folgendermaßen interpretiert:\n",
    "\n",
    "* Wenn $R^2 = 1$  ist, dann gibt es den perfekten linearen Zusammenhang und die\n",
    "  Modellfunktion ist eine sehr gute Anpassung an die Messdaten.\n",
    "* Wenn $R^2 = 0$ oder gar negativ ist, dann funktioniert die lineare\n",
    "  Modellfunktion überhaupt nicht. Dann ist das Modell schlechter als der einfache\n",
    "  Mittelwert.\n",
    "\n",
    "Auf der Seite [https://mathweb.de](https://mathweb.de) gibt es eine Reihe von\n",
    "Aufgaben und interaktiven Demonstrationen rund um die Mathematik. Insbesondere\n",
    "gibt es dort auch eine interaktive Demonstration des R²-Scores.\n",
    "\n",
    "**Mini-Übung**\n",
    "[https://lti.mint-web.de/examples/index.php?id=01010320]\n",
    "\n",
    "Drücken Sie auf den zwei kreisförmigen Pfeile rechts oben. Dadurch wird ein\n",
    "neuer Datensatz erzeugt. Die Messdaten sind durch grüne Punkte dargestellt, das\n",
    "lineare Regressionsmodell durch eine blaue Gerade. Im Titel wird der aktuelle\n",
    "und der optimale R²-Wert angezeigt. Ziehen Sie an den weißen Punkten, um die\n",
    "Gerade zu verändern. Schaffen Sie es, den optimalen R²-Score zu treffen?\n",
    "Beobachten Sie dabei, wie die Fehler (rot) kleiner werden.\n",
    "\n",
    "Wie ist nun der R²-Score für das trainierte lineare Regressionsmodell? Dazu\n",
    "verwenden wir die `score()`-Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = modell.score(X,y)\n",
    "print(f'Der R2-Score für das lineare Regressionsmodell ist: {r2_score:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd159e",
   "metadata": {},
   "source": [
    "Das lineare Regressionsmodell kann für die Trainingsdaten sehr gut die\n",
    "Verkaufspreise prognostizieren. Wie gut es allerdings noch unbekannte Daten\n",
    "prognostizieren könnte, ist ungewiss. Mit dem Thema Validierung werden wir uns\n",
    "einem späteren Kapitel noch detailliert beschäftigen.\n",
    "\n",
    "## Zusammenfassung und Ausblick\n",
    "\n",
    "In diesem Abschnitt haben wir das theoretische Modell der linearen Regression\n",
    "kennengelernt. Das Training eines linearen Regressionsmodells mit Scikit-Learn\n",
    "erfolgt wie üblich mit der `fit()`-Methode, die Prognose mit der\n",
    "`predict()`-Methode. Bewerten können wir Prognosequalität mit der\n",
    "`score()`-Methode. Im nächsten Kapitel betrachten wir die lineare Regression,\n",
    "bei der die Zielgröße von mehreren Merkmalen abhängt."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
