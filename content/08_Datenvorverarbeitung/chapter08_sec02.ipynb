{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb05820",
   "metadata": {},
   "source": [
    "# 8.2 Trainings- und Testdaten\n",
    "\n",
    "Bei den Entscheidungsbäumen und der linearen Regression haben wir mit der\n",
    "`score()`-Methode bewertet, wie viele der Daten durch das Modell korrekt\n",
    "prognostiziert wurden. Je näher der Score an 1 liegt, desto besser. Doch selbst\n",
    "ein perfekter Score bedeutet nicht zwangsläufig, dass das Modell optimal ist. Es\n",
    "könnte überangepasst (overfitted) sein und daher bei neuen, unbekannten Daten\n",
    "schlechte Prognosen liefern. Im Folgenden beschäftigen wir uns mit der\n",
    "Aufteilung von Daten in Trainings- und Testdaten.\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "* Sie verstehen, warum Daten in **Trainingsdaten** und **Testdaten** aufgeteilt\n",
    "  werden.\n",
    "* Sie können mit der Funktion **train_test_split()** Pandas-DataFrames in\n",
    "  Trainings- und Testdaten aufteilen.\n",
    "* Sie kennen das Konzept der **Kreuzvalidierung**.\n",
    "\n",
    "## Auswendiglernen nützt nichts\n",
    "\n",
    "Um die Herausforderungen bei der Modellauswahl zu verdeutlichen, betrachten wir\n",
    "einen künstlich generierten Datensatz. Angenommen, wir hätten die folgenden 20\n",
    "Messwerte erfasst und möchten ein Regressionsproblem lösen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "\n",
    "# Generierung Daten\n",
    "daten = pd.DataFrame()\n",
    "daten['Ursache'] = [1.8681193560547067, 0.18892899670288932, 1.8907374398595373, 0.8592639746974586, 0.7909152983890833, -1.1356420176784945, 1.905097819104967, -1.9750789791816405, -0.9880705504662242, -0.26083387038221684, 1.1175316871750098, -1.2092597015989877, 1.451972942396889, 1.933602708701251, -1.3446310343812051, 0.38933577573143685, -1.96405560932978, -0.45371486942548245, -1.8233597682740017, 1.8266118708569437]\n",
    "daten['Wirkung'] = [18.06801933135814, 0.09048390063552635, 18.29951272892001, 4.02392603643671, 1.97091878521032, 6.799411114666941, 17.540101218695103, 21.051664199041685, 5.604758672240995, 0.38630710692300024, 5.261393705782588, 7.365977868421521, 10.701020062336028, 17.48514901635516, 11.263523310016517, 1.1522069460363902, 20.979929897937023, -0.08352624016486021, 18.258951764602635, 15.321589041941028]\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(daten, x = 'Ursache', y = 'Wirkung', title= 'Künstlich generierte Messdaten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55822409",
   "metadata": {},
   "source": [
    "Nun würden wir das folgende Modell implementieren. Der Name des Modells sagt\n",
    "bereits alles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028dc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class AuswendigLerner:\n",
    "    def __init__(self) -> None:\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89b9a7",
   "metadata": {},
   "source": [
    "Wir trainieren unser Modell und lassen es dann bewerten. Um nicht selbst den\n",
    "R²-Score implementieren zu müssen, verwenden wir die allgemeine Funktion aus\n",
    "Scikit-Learn (siehe [Dokumentation Scikit-Learn →\n",
    "r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ec2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaption der Daten\n",
    "X = daten[['Ursache']]\n",
    "y = daten['Wirkung']\n",
    "\n",
    "# Auswahl Modell und Training\n",
    "mein_super_modell = AuswendigLerner()\n",
    "mein_super_modell.fit(X, y)\n",
    "\n",
    "# prediction\n",
    "y_prognose = mein_super_modell.predict(X)\n",
    "\n",
    "# check quality\n",
    "score = r2_score(y,y_prognose)\n",
    "print(f'Der R2-Score ist: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e0401",
   "metadata": {},
   "source": [
    "Ein R²-Score von 1, unser Modell scheint perfekt zu funktionieren! Doch wie\n",
    "prognostiziert es neue Daten? Das Modell funktioniert zwar hervorragend für die\n",
    "gegebenen Trainingsdaten, ist jedoch **nicht verallgemeinerbar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd09077",
   "metadata": {},
   "outputs": [],
   "source": [
    "mein_super_modell.predict([[1.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417247b0",
   "metadata": {},
   "source": [
    "Anstatt für den x-Wert $1.3$ (Ursache) eine Prognose zu treffen, gibt das Modell\n",
    "einfach die auswendig gelernten y-Werte (Wirkungen) aus.\n",
    "\n",
    "## Daten für später aufheben\n",
    "\n",
    "Bei der Modellauswahl und dem Training des Modells müssen wir zusätzlich\n",
    "sicherstellen, dass das Modell verallgemeinerbar ist, das heißt, dass es auch\n",
    "für neue, zukünftige Daten verlässliche Prognosen liefern kann. Da wir jedoch\n",
    "sofort abschätzen wollen, wie gut das Modell auf neue Daten reagiert, und nicht\n",
    "warten möchten, bis die nächsten Messungen vorliegen, legen wir jetzt schon\n",
    "einen Teil der vorhandenen Daten zur Seite. Diese Daten nennen wir\n",
    "**Testdaten**. Die verbleibenden Daten verwenden wir für das Training des\n",
    "Modells, sie heißen **Trainingsdaten**. Später nutzen wir die Testdaten, um zu\n",
    "überprüfen, wie gut das Modell bei Daten funktioniert, die nicht zum Training\n",
    "verwendet wurden.\n",
    "\n",
    "Für die Aufteilung in Trainings- und Testdaten verwenden wir eine dafür\n",
    "vorgesehene Funktion von Scikit-Learn namens `train_test_split()` (siehe\n",
    "[Dokumentation Scikit-Learn →\n",
    "train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)).\n",
    "Diese Funktion müssen wir aus dem Modul `sklearn.model_selection` importieren.\n",
    "Dann übergeben wir `train_test_split()` die Daten, die aufgeteilt werden sollen,\n",
    "und erhalten als Rückgabe zwei DataFrames: Der erste enthält die Trainingsdaten,\n",
    "der zweite die Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd476e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "daten_train, daten_test = train_test_split(daten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d5d4d",
   "metadata": {},
   "source": [
    "Nun wollen wir sehen, welche Datenpunkte zu den Trainingsdaten und welche zu den\n",
    "Testdaten gehören. Dazu fügen wir dem Datensatz ein neues Merkmal hinzu und\n",
    "füllen es mit den Strings `'Trainingsdaten'` bzw. `'Testdaten'`. Anschließend\n",
    "visualisieren wir die Datenpunkte wie oben, wobei die Punkte entsprechend ihrer\n",
    "Zugehörigkeit (Trainings- oder Testdaten) eingefärbt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd04425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anreicherung der Daten mit dem Splitstatus\n",
    "daten.loc[daten_train.index,'Splitstatus'] = 'Trainingsdaten'\n",
    "daten.loc[daten_test.index, 'Splitstatus'] = 'Testdaten'\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(daten, x = 'Ursache', y = 'Wirkung', color='Splitstatus', \n",
    "title='Künstlich generierte Messdaten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc082f1",
   "metadata": {},
   "source": [
    "Standardmäßig hält die Funktion `train_test_split()` 25 % der Daten als\n",
    "Testdaten zurück. Ein schnelles Zählen der fünf Testdatenpunkte bestätigt dies.\n",
    "Die Auswahl der Testdaten erfolgt zufällig, sodass jeder Durchlauf des Codes\n",
    "eine andere Aufteilung der Daten erzeugt.\n",
    "\n",
    "Die Funktion bietet aber auch Optionen, um die Aufteilung nach eigenen Wünschen\n",
    "anzupassen:\n",
    "\n",
    "* `test_size`: Mit der Option `test_size` kann ein anderer Anteil als 25 % für\n",
    "  die Testdaten festgelegt werden. Möchte man zum Beispiel nur 10 % der Daten\n",
    "  als Testdaten zurückhalten, kann man `test_size=0.1` einstellen. Der Anteil\n",
    "  wird als Float zwischen 0.0 und 1.0 angegeben. Verwendet man stattdessen einen\n",
    "  Integer, interpretiert Scikit-Learn diesen als Anzahl der Testdatenpunkte.\n",
    "  `test_size=7` bedeutet also, dass sieben Datenpunkte als Testdaten verwendet\n",
    "  werden.\n",
    "* `random_state`: Die zufällige Auswahl der Testdaten erfolgt durch einen\n",
    "  Zufallszahlengenerator, der bei jedem Durchlauf neu gestartet wird. Wenn wir\n",
    "  zwar eine zufällige Auswahl wollen, aber den Neustart des\n",
    "  Zufallszahlengenerators verhindern möchten, können wir den Ausgangszustand des\n",
    "  Generators mit einem festen Wert (Integer) festlegen. Das ist vor allem für\n",
    "  Präsentationen oder Lehrmaterialien nützlich.\n",
    "* `shuffle`: Die Option `shuffle` bestimmt, ob die Daten vor der Aufteilung\n",
    "  durchmischt werden. Der Standard ist `True`, d.h. die Datenpunkte werden\n",
    "  zufällig durchmischt, bevor sie aufgeteilt werden. Wird diese Option auf\n",
    "  `False` gesetzt, behalten die Daten ihre ursprüngliche Reihenfolge. Bei einem\n",
    "  üblichen Split von 80/20 in Trainingsdaten und Testdaten werden die ersten 80\n",
    "  \\% für die Trainingsdaten genommen und die letzten 20 % für die Testdaten. Sind\n",
    "  die Daten sortiert, kann es dadurch zu Verzerrungen kommen. Kommen\n",
    "  beispielsweise erst alle billigen Autos und dann die teuren, lernt das\n",
    "  ML-Modell mit den billigeren Autos und testet mit den teureren Autos.\n",
    "* `stratify`: Diese Option ist vor allem wichtig, wenn die Verteilung zwischen\n",
    "  verschiedenen Klassen erhalten bleiben soll. Sind im gesamten Datensatz 30 \\%\n",
    "  der Autos Diesel-Fahrzeuge, sollen auch in den Trainingsdaten 30 \\% der Autos\n",
    "  Diesel-Fahrzeuge sein. Diese Option erfordert, dass die Option `shuffle` auf\n",
    "  `True` gesetzt ist. Mehr Informationen zum Gebrauch von `stratify` finden wir\n",
    "  in der [Dokumentation Scikit-Learn →\n",
    "  train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "Nun verwenden wir `train_test_split` für unsere Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41419173",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_train, daten_test = train_test_split(daten, test_size=7, random_state=0)\n",
    "\n",
    "# Aktualisierung des Splitstatus\n",
    "daten.loc[daten_train.index,'Splitstatus'] = 'Trainingsdaten'\n",
    "daten.loc[daten_test.index, 'Splitstatus'] = 'Testdaten'\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(daten, x = 'Ursache', y = 'Wirkung', color='Splitstatus', \n",
    "title='Künstlich generierte Messdaten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704362a",
   "metadata": {},
   "source": [
    "## Idee der Kreuzvalidierung\n",
    "\n",
    "Das Zurückhalten eines Teils der Daten als Testdaten hat den Nachteil, dass\n",
    "weniger Daten für das Training zur Verfügung stehen. Besonders bei kleinen\n",
    "Datensätzen kann dies dazu führen, dass das Modell ungenau oder schlecht\n",
    "trainiert wird. Hier kommt die Kreuzvalidierung ins Spiel.\n",
    "\n",
    "Die Idee der **Kreuzvalidierung** ist, die Daten in mehrere Teilmengen zu\n",
    "unterteilen und das Modell mehrmals zu trainieren und zu testen, um die Leistung\n",
    "besser beurteilen zu können. Schauen wir uns zunächst die zweifache\n",
    "Kreuzvalidierung an:\n",
    "\n",
    "Bei der zweifachen Kreuzvalidierung teilen wir die Daten in zwei Teilmengen, A\n",
    "und B. Das Modell wird dann zweimal trainiert und getestet: einmal mit A als\n",
    "Trainingsdaten und B als Testdaten, und einmal umgekehrt. Die endgültige\n",
    "Modellbewertung ergibt sich aus dem Durchschnitt der beiden Testergebnisse.\n",
    "\n",
    "Die dreifache Kreuzvalidierung funktioniert ähnlich, mit dem Unterschied, dass\n",
    "die Daten in drei Teilmengen A, B und C aufgeteilt werden. In drei Durchläufen\n",
    "wird jeweils mit zwei der Teilmengen trainiert und mit der dritten getestet:\n",
    "\n",
    "* Im ersten Durchlauf wird mit A und B trainiert und mit C getestet.\n",
    "* Im zweiten Durchlauf wird mit B und C trainiert und mit A getestet.\n",
    "* Im dritten Durchlauf wird mit A und C trainiert und mit B getestet. Am Ende\n",
    "wird der Durchschnitt der drei Testergebnisse als Maß für die Modellleistung\n",
    "verwendet.\n",
    "\n",
    "Dieses Verfahren lässt sich auf beliebig viele Teilmengen erweitern.\n",
    "Scikit-Learn bietet dafür auch spezielle Funktionen zur effizienten Umsetzung\n",
    "der Kreuzvalidierung. Eine detailliertere Betrachtung dieser Techniken erfolgt\n",
    "jedoch in einem späteren Kapitel. An dieser Stelle soll lediglich das Konzept\n",
    "der Kreuzvalidierung eingeführt werden.\n",
    "\n",
    "## Zusammenfassung und Ausblick\n",
    "\n",
    "In diesem Abschnitt haben wir die Aufteilung von Daten in Trainings- und\n",
    "Testdaten kennengelernt und die Funktion `train_test_split()` verwendet. Diese\n",
    "Funktion wird uns in zukünftigen Kapiteln und Projekten begleiten. Zudem haben\n",
    "wir eine erste Einführung in die Kreuzvalidierung erhalten, die wir später\n",
    "ausführlicher behandeln werden."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
