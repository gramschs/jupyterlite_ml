{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c44e1a",
   "metadata": {},
   "source": [
    "# 12.3 Neuronale Netze mit Scikit-Learn\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "* Sie wissen, was die **Architektur** eines neuronalen Netzes ist.\n",
    "* Sie können mit Scikit-Learn ein neuronales Netz zur Klassifikation trainieren.\n",
    "* Sie wissen, dass neuronale Netze sensitiv auf unskalierte Daten reagieren\n",
    "  und daher skaliert werden müssen.\n",
    "* Sie können neuronale Netze mit Gittersuche und Kreuzvalidierung trainieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee628b",
   "metadata": {},
   "source": [
    "## Neuronale Netze zur Klassifikation\n",
    "\n",
    "Schauen wir uns an, wie das Training eines neuronalen Netzes in Scikit-Learn\n",
    "funktioniert. Dazu erzeugen wir zunächst künstliche Daten für eine binäre\n",
    "Klassifikationsaufgabe, splitten sie in Trainings- und Testdaten und lassen sie\n",
    "visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generiere künstliche Daten\n",
    "X, y = make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "# Split Trainings- / Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)\n",
    "\n",
    "# Konvertierung in ein DataFrame-Objekt für Plotly Express\n",
    "df = pd.DataFrame({\n",
    "    'Feature 1': X[:, 0],\n",
    "    'Feature 2': X[:, 1],\n",
    "    'Category': pd.Series(y, dtype='category')\n",
    "})\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(df, x='Feature 1', y='Feature 2', color='Category',\n",
    "                 title='Künstliche Daten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6cea9",
   "metadata": {},
   "source": [
    "Die neuronalen Netze sind in dem Untermodul `sklearn.neural_network`. Da es sich\n",
    "um eine Klassifikationsaufgabe handelt, laden wir das Multilayer-Perzeptron mit\n",
    "`MLPClassifier`. Mehr Details dazu können wir in der Dokumentation\n",
    "\n",
    "> [https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "\n",
    "nachlesen. Wir lassen das neuronale Netz mit `.fit()` trainieren und geben die\n",
    "Scores für die Trainings- und Testdaten mit `.score()` aus. Aus didaktischen\n",
    "Gründen fixieren wir den Zufallsseed mit `random_state=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63cef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Auswahl des Modells\n",
    "neuronales_netz = MLPClassifier(random_state=0)\n",
    "\n",
    "# Training\n",
    "neuronales_netz.fit(X_train, y_train)\n",
    "\n",
    "# Validierung \n",
    "score_train = neuronales_netz.score(X_train, y_train)\n",
    "score_test = neuronales_netz.score(X_test, y_test)\n",
    "print(f'Score für Trainingsdaten: {score_train:.2f}')\n",
    "print(f'Score für Testdaten: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cee58b",
   "metadata": {},
   "source": [
    "Beim Training des neuronalen Netzes erscheint die Warnung: `Stochastic\n",
    "Optimizer: Maximum iterations (200) reached and the optimization hasn't\n",
    "converged yet.`. Zum Bestimmen der Gewichte des neuronalen Netzes wird ein\n",
    "iteratives Verfahren verwendet, das Schritt für Schritt die optimalen Gewichte\n",
    "berechnet. Iterative Verfahren können in eine Endlosschleife geraten. Um das zu\n",
    "verhindern, wird in der Regel die Anzahl der Schritte (Iterationen) begrenzt.\n",
    "Die Warnung besagt, dass in unserem Beispiel die Suche nach den optimalen\n",
    "Gewichten des neuronalen Netzes nach der fest eingestellten Anzahl von 200\n",
    "Schritten eingestellt wurde. Wir erhöhen diese Zahl auf 2000 mit dem optionalen\n",
    "Argument `max_iter=2000` und wiederholen das Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7238a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl des Modells mit maximal 2000 Iterationen\n",
    "neuronales_netz = MLPClassifier(max_iter=2000, random_state=0)\n",
    "\n",
    "# Training\n",
    "neuronales_netz.fit(X_train, y_train)\n",
    "\n",
    "# Validierung \n",
    "score_train = neuronales_netz.score(X_train, y_train)\n",
    "score_test = neuronales_netz.score(X_test, y_test)\n",
    "print(f'Score für Trainingsdaten: {score_train:.2f}')\n",
    "print(f'Score für Testdaten: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55610a8",
   "metadata": {},
   "source": [
    "Jetzt ist die Anzahl der Schritte ausreichend, um das neuronale Netz zu\n",
    "trainieren.\n",
    "\n",
    "**Hinweis: Daten skalieren**\n",
    "\n",
    "In der Regel ist das Skalieren der Daten besser als das Erhöhen der maximalen\n",
    "Anzahl an Iterationen. Im Maschinenbau messen wir oft Größen mit sehr\n",
    "unterschiedlichen Einheiten: Temperaturen (20-100°C), Drücke (1-200 bar) oder\n",
    "Drehzahlen (0-3000 rpm). Liegen Werte in recht unterschiedlichen Größenordnungen\n",
    "vor, so wird das Training erschwert. Daher ist es sinnvoll, die Daten auf\n",
    "ähnliche Größenordnungen zu skalieren.\n",
    "\n",
    "In dem obigen Beispiel sind die künstlichen Daten jedoch bereits in einem\n",
    "ähnlichen Größenbreich, so dass wir hier keine Skalierung vornehmen müssen.\n",
    "\n",
    "## Architektur des neuronalen Netzes ändern\n",
    "\n",
    "Neuronale Netze sind zusammengesetzte künstliche Neuronen. Aber welche\n",
    "Zusammensetzung liegt hier vor? Wie viele versteckte Schichten gibt es, wie\n",
    "viele Neuronen sind in den einzelnen versteckten Schichten? Welche\n",
    "Aktivierungsfunktion wurde verwendet? Die zentralen Bestandteile eines\n",
    "neuronalen Netzes werden **Architektur** des neuronalen Netzes genannt.\n",
    "\n",
    "Die Voreinstellung für die Anzahl der versteckten Schichten ist\n",
    "`hidden_layer_sizes=(100,)`. Dem optionalen Argument `hidden_layer_sizes` wird\n",
    "ein Tupel mit ganzen Zahlen übergeben, wobei hier das Tupel nur eine Zahl\n",
    "enthält, nämlich 100. Das bedeutet, dass das neuronale Netz eine versteckte\n",
    "Schicht hat und diese aus 100 Neuronen besteht. Besteht das Tupel aus mehreren\n",
    "Zahlen, z.B. `(50, 20, 40)`, dann gibt die die erste Zahl in dem Tupel die\n",
    "Anzahl der Neuronen in der ersten versteckten Schicht an (also 50), die zweite\n",
    "Zahl die Anzahl der Neuronen in der zweiten Schicht (also 20) und immer so\n",
    "weiter.\n",
    "\n",
    "Jetzt wo wir wissen, dass das neuronale Netz mit der Standardeinstellung\n",
    "`MLPClassifier()` eine versteckte Schicht mit 100 Neuronen hat, können wir uns\n",
    "überlegen, wie viele Gewichte das Modell hat. Bei zwei Merkmalen, einer\n",
    "versteckten Schicht mit 100 Neuronen und einer Ausgabe brauchen wir insgesamt 2\n",
    "x 100 + 100 + 100 x 1 = 401 Parameter (Gewichte und Bias-Einheiten).\n",
    "Gleichzeitig haben wir nur 100 Datenpunkte, also nur ein Viertel so viele\n",
    "Informationen wie Parameter. Damit ist die Gefahr groß, dass Overfitting\n",
    "vorliegt. Wir wählen zwei versteckte Schichten mit jeweils zwei Neuronen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl des Modells\n",
    "neuronales_netz = MLPClassifier(max_iter=2000, hidden_layer_sizes=(2,2), random_state=0)\n",
    "\n",
    "# Training\n",
    "neuronales_netz.fit(X_train, y_train)\n",
    "\n",
    "# Validierung \n",
    "score_train = neuronales_netz.score(X_train, y_train)\n",
    "score_test = neuronales_netz.score(X_test, y_test)\n",
    "print(f'Score für Trainingsdaten: {score_train:.2f}')\n",
    "print(f'Score für Testdaten: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae4c65",
   "metadata": {},
   "source": [
    "Die Scores für Trainings- und Testdaten sind schlecht. Wir zeichnen die\n",
    "Entscheidungsgrenzen ein, um zu sehen, wo das neuronale Netz die Trennlinien\n",
    "zieht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e761dea",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Create grid for contour plot\n",
    "gridX, gridY = np.meshgrid(np.linspace(-1.5, 1.5, 50), np.linspace(-1.5, 1.5, 50))\n",
    "gridZ = neuronales_netz.predict_proba(np.column_stack([gridX.ravel(), gridY.ravel()]))[:, 1]\n",
    "Z = gridZ.reshape(gridX.shape)\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = go.Scatter(x=df['Feature 1'], y=df['Feature 2'], mode='markers',\n",
    "                     marker=dict(color=df['Category'], colorscale='BlueRed_r'))\n",
    "\n",
    "# Create contour plot\n",
    "contour = go.Contour(x=np.linspace(-1.5, 1.5, 50), y=np.linspace(-1.5, 1.5, 50), z=Z, \n",
    "                     opacity=0.2, colorscale='BlueRed_r')\n",
    "\n",
    "# Create figure and add plots\n",
    "fig = go.Figure()\n",
    "fig.add_trace(contour)\n",
    "fig.add_trace(scatter)\n",
    "fig.update_layout(title='Künstliche Messdaten und Entscheidungsgrenzen des neuronalen Netzes',\n",
    "                  xaxis_title='Feature 1',\n",
    "                  yaxis_title='Feature 2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45fbf9",
   "metadata": {},
   "source": [
    "Dieses neuronale Netz scheint nicht komplex genug zu sein, um die Daten korrekt\n",
    "zu klassifizieren.\n",
    "\n",
    "**Mini-Übung**\n",
    "\n",
    "Experimentieren Sie mit verschiedenen Architekturen:\n",
    "1. Testen Sie `hidden_layer_sizes=(20,)`, also eine Schicht mit 20 Neuronen.\n",
    "2. Testen Sie `hidden_layer_sizes=(15, 10, 5)`, also drei Schichten.\n",
    "3. Welche Architektur funktioniert am besten?\n",
    "4. Was passiert mit sehr großen Netzen wie `hidden_layer_sizes=(100, 100)`?\n",
    "\n",
    "Probieren wir zwei versteckte Schichten mit jeweils fünf Neuronen aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ac49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl des Modells\n",
    "neuronales_netz = MLPClassifier(max_iter=2000, hidden_layer_sizes=(5,5), random_state=0)\n",
    "\n",
    "# Training\n",
    "neuronales_netz.fit(X_train, y_train)\n",
    "\n",
    "# Validierung \n",
    "score_train = neuronales_netz.score(X_train, y_train)\n",
    "score_test = neuronales_netz.score(X_test, y_test)\n",
    "print(f'Score für Trainingsdaten: {score_train:.2f}')\n",
    "print(f'Score für Testdaten: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874be7d4",
   "metadata": {},
   "source": [
    "Erneut lassen wir die Entscheidungsgrenzen visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ce09e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "gridZ = neuronales_netz.predict_proba(np.column_stack([gridX.ravel(), gridY.ravel()]))[:, 1]\n",
    "Z = gridZ.reshape(gridX.shape)\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = go.Scatter(x=df['Feature 1'], y=df['Feature 2'], mode='markers',\n",
    "                     marker=dict(color=df['Category'], colorscale='BlueRed_r'))\n",
    "\n",
    "# Create contour plot\n",
    "contour = go.Contour(x=np.linspace(-1.5, 1.5, 50), y=np.linspace(-1.5, 1.5, 50), z=Z, \n",
    "                     opacity=0.2, colorscale='BlueRed_r')\n",
    "\n",
    "# Create figure and add plots\n",
    "fig = go.Figure()\n",
    "fig.add_trace(contour)\n",
    "fig.add_trace(scatter)\n",
    "fig.update_layout(title='Künstliche Messdaten und Entscheidungsgrenzen des neuronalen Netzes',\n",
    "                  xaxis_title='Feature 1',\n",
    "                  yaxis_title='Feature 2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95347ac",
   "metadata": {},
   "source": [
    "Die Scores für Trainings- und Testdaten sind gut und die Entscheidungsgrenzen\n",
    "sind plausibel.\n",
    "\n",
    "## Optimierung mit Gittersuche\n",
    "\n",
    "Bisher haben wir die Architektur manuell angepasst. Mit der Gittersuche (Grid\n",
    "Search) können wir diesen Prozess automatisieren. Die Gittersuche testet\n",
    "systematisch verschiedene Kombinationen von Parametern und findet die beste\n",
    "Konfiguration. Dabei wird jede Kombination mit Kreuzvalidierung (Cross\n",
    "Validation) getestet: Die Trainingsdaten werden in 5 Teile aufgeteilt und das\n",
    "Modell wird 5-mal trainiert, wobei jedes Mal ein anderer Teil zur Validierung\n",
    "dient. Neben der Anzahl der versteckten Schichten ändern wir auch noch die\n",
    "Aktivierungsfunktion. Auch wenn es eigentlich nicht nötig ist, skalieren wir die\n",
    "Daten, so wie es in der Regel notwendig ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Künstliche Daten generieren\n",
    "X, y = make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "# Daten skalieren (wichtig für neuronale Netze!)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, random_state=0\n",
    ")\n",
    "\n",
    "# Definition des Suchraums\n",
    "# Wir testen verschiedene Architekturen und Lernraten\n",
    "gitter = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (5,),           # 1 Schicht mit 5 Neuronen\n",
    "        (10,),          # 1 Schicht mit 10 Neuronen\n",
    "        (5, 5),        # 2 Schichten mit je 5 Neuronen\n",
    "        (10, 5),       # 2 Schichten mit 10 und 5 Neuronen\n",
    "        (10, 10),      # 2 Schichten mit je 10 Neuronen\n",
    "    ],\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularisierung (verhindert Overfitting)\n",
    "    'solver': ['lbfgs', 'adam']      # Solver\n",
    "}\n",
    "\n",
    "# Basismodell erstellen\n",
    "basismodell = MLPClassifier(max_iter=5000, random_state=0)\n",
    "\n",
    "# Gittersuche mit 5-facher Kreuzvalidierung\n",
    "gittersuche = GridSearchCV(\n",
    "    estimator=basismodell,\n",
    "    param_grid=gitter,\n",
    "    cv=5  # 5-fache Kreuzvalidierung\n",
    ")\n",
    "\n",
    "# Suche starten\n",
    "print('Starte Gittersuche...')\n",
    "gittersuche.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter ausgeben\n",
    "print('Ergebnisse der Gittersuche:')\n",
    "print(f'beste Parameter: {gittersuche.best_params_}')\n",
    "print(f'bester Score (Kreuzvalidierung): {gittersuche.best_score_:.2f}')\n",
    "\n",
    "# Bestes Modell auf Testdaten evaluieren\n",
    "bestes_modell = gittersuche.best_estimator_\n",
    "test_score = bestes_modell.score(X_test, y_test)\n",
    "print(f\"Score auf Testdaten: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e9a23",
   "metadata": {},
   "source": [
    "Für das beste Modell sehen die Entscheidungsgrenzen wie folgt aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468f04c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "gridX, gridY = np.meshgrid(np.linspace(-2.5, 2.5, 100), np.linspace(-2.5, 2.5, 100))\n",
    "gridZ = bestes_modell.predict_proba(np.column_stack([gridX.ravel(), gridY.ravel()]))[:, 1]\n",
    "Z = gridZ.reshape(gridX.shape)\n",
    "\n",
    "# Create scatter plot\n",
    "scatter = go.Scatter(x=X_scaled[:,0], y=X_scaled[:,1], mode='markers',\n",
    "                     marker=dict(color=df['Category'], colorscale='BlueRed_r'))\n",
    "\n",
    "# Create contour plot\n",
    "contour = go.Contour(x=np.linspace(-2.5, 2.5, 100), y=np.linspace(-2.5, 2.5, 100), z=Z, \n",
    "                     opacity=0.2, colorscale='BlueRed_r')\n",
    "\n",
    "# Create figure and add plots\n",
    "fig = go.Figure()\n",
    "fig.add_trace(contour)\n",
    "fig.add_trace(scatter)\n",
    "fig.update_layout(title='Künstliche Messdaten und Entscheidungsgrenzen des besten neuronalen Netzes',\n",
    "                  xaxis_title='Feature 1',\n",
    "                  yaxis_title='Feature 2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efd5a5",
   "metadata": {},
   "source": [
    "Es ist schwierig, eine gute Architektur des neuronalen Netzes zu finden. Auch\n",
    "fällt das Ergebnis jedesmal ein wenig anders aus, weil im Hintergrund\n",
    "stochastische Verfahren für das Trainieren der Gewichte benutzt werden. Aus\n",
    "diesem Grund sollten neuronale Netze nur eingesetzt werden, wenn sehr große\n",
    "Datenmengen vorliegen und auch dann noch ist das Finden der besten Architektur\n",
    "eine große Herausforderung.\n",
    "\n",
    "## Zusammenfassung und Ausblick\n",
    "\n",
    "Neuronale Netze sind ein sehr mächtiges Werkzeug, erfordern aber auch große\n",
    "Datenmengen und ein sorgfältiges Training. In vielen Fällen sollten erst\n",
    "einfachere ML-Modelle wie beispielsweise das Random-Forest-Modell ausprobiert\n",
    "werden, das in der Regel einen guten Kompromiss zwischen Geschwindigkeit und\n",
    "Genauigkeit darstellt, bevor neuronale Netze eingesetzt werden."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3",
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
